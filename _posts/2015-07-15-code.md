---
layout: post
title: Creating RAG application using Langgraph
date: 2024-03-01 15:09:00
description: stateful langgraph nodes for RAG applications rather than multiple tools selection in LCEL
tags: rag nlp langchain llm
disqus_comments: true
categories: nlp
---



## Prerequisites
1. Good Knowledge on langchain, creating agents used for multiple tools selections
2. Well-versed in retrieval-augmented generations, vector databases, and text embeddings

## Learning Objectives
By the end of this post, all readers will be able to:
1. Understand the difference between langchain agents with multiple tools selections and langgraphs
2. Create a langgraph agentic rag using stateful nodes capable of making logical decisions using LLMs


## Langchain Vs Langgraph


<p style="text-align:justify;">
<img   src="/assets/blogs/langgraph-agentic-rag/langgraph.webp" style="float: right;padding:20px">

Langchain is constructed upon the fundamental principle of a sequential acyclic flow of execution, spanning from user inquiry to the generation of results by the Language Model (LLM). 
<br>
In RAG (Retrieval-Augmented Generation), the procedural flow within the application starts with the user query, progresses through stages such as database extraction, tool selection, context enrichment, and ultimately finishes at result generation. Furthermore, this process may also encompass evaluation, query transformations, and similar steps. The essence of Langchain lies in its utilization of interconnected "chains," wherein each element is systematically linked in a sequential fashion. 
<br><br>
It's important to understand that the decision-making process in this context operates sequentially. When choices are made, they set the course for subsequent actions, creating a flow of information. What's significant about this approach is the absence of a feedback loop or the opportunity for re-evaluation based on outcomes. Among its various capabilities, langgraph is specifically designed to introduce a cyclic, stateful, multi-actor application framework using LLMs. Previously, Langchain agents could only re-execute a single action using CoT prompts like ReAct. They could assess the outcome, observe results, and potentially adjust course. 
<br><br>
However, the ability to reprocess multiple steps of execution was unavailable until the introduction of langgraph. With langgraph, we now have the capability to re-execute multiple elements in a feedback loop fashion, enabling a more iterative approach to decision-making and action.
<br>
Agents developed within langgraph will possess the capability to make decisions, assess their effectiveness, and if necessary, rerun processes to enhance output. This functionality extends the LangChain Expression Language by facilitating the coordination of multiple chains or actors across various stages of computation in a cyclic fashion, as stated by LangChain. With langgraph, you now have the flexibility to outline an application resembling a flowchart, with each decision node rooted in the logical determinations of LLMs. This enables a structured and iterative approach to application development, allowing for refinement and optimization at every step.
<br><br><br>

<b>Now, in this blog post, we will be creating a RAG agent using langgraph by designing a sequence of execution nodes and the overall flow of the application.</b>
</p>

<br>

## RAG using agents in langgraph

<br>
{% highlight c++ linenos %}
{% endhighlight %}

### Installations
The first and foremost thing to do is to make sure all the necessary libraries are installed. Make sure you have the upgraded version of langchain because a lot of modules are segregated out of langchain to openai, community and hub.

{% highlight c++ linenos %}
    pip install langchain_community langchain-openai langchainhub chromadb langchain langgraph
{% endhighlight %}

### Load OPENAI API keys
We will use the python-dotenv package to load our api keys.

{% highlight c++ linenos %}
    import os

    from dotenv import load_dotenv, find_dotenv

    # read local .env file
    _ = load_dotenv(find_dotenv())
{% endhighlight %}



### Indexing

The initial step in any machine learning projects is to collect the data and conduct pre processing for further usage. 

1. In this step here, we will be loading our data from three blog posts from Lilian Weng using the `WebBaseLoader` from langchain that loads the data in the form of txt files in a list. 
2. Once each links are processed in a list of `Document` objects in langchain, we will start creating the chunks.
3. We will use `RecursiveCharacterTextSplitter` with `chunk_size = 100` and `chunk_overlap = 50` to create document chunks
4. Creating a vector store using `chromadb`.

{% highlight c++ linenos %}
    # necessary imports
    from langchain.text_splitter import RecursiveCharacterTextSplitter
    from langchain_community.document_loaders import WebBaseLoader
    from langchain_community.vectorstores import Chroma
    from langchain_openai import OpenAIEmbeddings

    # data sources
    urls = [
        "https://lilianweng.github.io/posts/2023-06-23-agent/",
        "https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/",
        "https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/",
    ]

    # get the documents in txt based formats
    docs = [WebBaseLoader(url).load() for url in urls]
    docs_list = [item for sublist in docs for item in sublist]

    # split the documents into chunks
    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
        chunk_size=100, chunk_overlap=50
    )
    doc_splits = text_splitter.split_documents(docs_list)
    
    # create a chromadb based on the chunks above
    # each chunks are embedded using OPENAI embeddings and the database is named as "rag-chroma"
    vectorstore = Chroma.from_documents(
        documents=doc_splits,
        collection_name="rag-chroma",
        embedding=OpenAIEmbeddings(),
    )

    # instantiate a vector store backed retriever
    retriever = vectorstore.as_retriever()
{% endhighlight %}

We will now create an agent tool that the agent can access while retreiving documents from the chroma database. This is very similar to what we do in LCEL / langchain while creating a tool and a tool executor.

{% highlight c++ linenos %}
    from langchain.tools.retriever import create_retriever_tool

    # Tool Definition with the name of the tool and its description
    tool = create_retriever_tool(
        retriever,
        "retrieve_blog_posts",
        "Search and return information about Lilian Weng blog posts on LLM agents, prompt engineering, and adversarial attacks on LLMs.",
    )

    tools = [tool]

    from langgraph.prebuilt import ToolExecutor
    tool_executor = ToolExecutor(tools)
    # tool_executor that can be called with agent

{% endhighlight %}

### States in a langgraph

A state in a langgraph is very similar to attributes in a class object. Whenever a flow execution moves from one node to another node, the output of nodes are written in the states object (overridden or added). Overridden means change in state whereas  addition means collection of states. For example: chat messages will be added where as grades of documents will be overidden.
<br>

You can think of states as sessions values as well like in streamlit (if you have used streamlit) or cache.
<br>

In the following example, we define a `AgentState` class that collects all the messages generated in the execution. It is nothing but a dictionary with key, value pairs.

{% highlight c++ linenos %}
    import operator
    from typing import Annotated, Sequence, TypedDict

    from langchain_core.messages import BaseMessage


    class AgentState(TypedDict):
        messages: Annotated[Sequence[BaseMessage], operator.add]

    # Here, the opetor.add is defined so that we can simply pass the Sequence[BaseMessage] as parameters
    # and no need to define add functions. like AgentState([k, v])
{% endhighlight %}


### Nodes of execution
<img src="/assets/blogs/langgraph-agentic-rag/state-flow.png" width="100%" align="center">


#### imports
{% highlight c++ linenos %}
    from langchain import hub
    from langchain.output_parsers import PydanticOutputParser
    from langchain.prompts import PromptTemplate
    from langchain.tools.render import format_tool_to_openai_function
    from langchain_core.utils.function_calling import convert_to_openai_tool
    from langchain_core.messages import BaseMessage, FunctionMessage
    from langchain.output_parsers.openai_tools import PydanticToolsParser
    from langchain_core.pydantic_v1 import BaseModel, Field
    from langchain_openai import ChatOpenAI
    from langgraph.prebuilt import ToolInvocation
    from langchain_core.output_parsers import StrOutputParser
{% endhighlight %}



#### agent node
{% highlight c++ linenos %}

    def agent(state):
        """
        Invokes the agent model to generate a response based on the current state. Given
        the question, it will decide to retrieve using the retriever tool, or simply end.

        Args:
            state (messages): The current state

        Returns:
            dict: The updated state with the agent response apended to messages
        """
        print("---CALL AGENT---")
        messages = state["messages"]
        model = ChatOpenAI(
            model_name="gpt-3.5-turbo",
            temperature=0,
        )
        functions = [format_tool_to_openai_function(t) for t in tools]
        model = model.bind_functions(functions)
        response = model.invoke(messages)
        # We return a list, because this will get added to the existing list
        return {"messages": [response]}
{% endhighlight %}

#### retreive node
{% highlight c++ linenos %}

    def retrieve(state):
        """
        Uses tool to execute retrieval.

        Args:
            state (messages): The current state

        Returns:
            dict: The updated state with retrieved docs
        """
        print("---EXECUTE RETRIEVAL---")
        messages = state["messages"]
        # Based on the continue condition
        # we know the last message involves a function call
        last_message = messages[-1]
        # We construct an ToolInvocation from the function_call
        action = ToolInvocation(
            tool=last_message.additional_kwargs["function_call"]["name"],
            tool_input=json.loads(
                last_message.additional_kwargs["function_call"]["arguments"]
            ),
        )
        # We call the tool_executor and get back a response
        response = tool_executor.invoke(action)
        function_message = FunctionMessage(content=str(response), name=action.tool)

        # We return a list, because this will get added to the existing list
        return {"messages": [function_message]}
{% endhighlight %}

#### should_retreive node
{% highlight c++ linenos %}
    def should_retrieve(state):
        """
        Decides whether the agent should retrieve more information or end the process.

        This function checks the last message in the state for a function call. If a function call is
        present, the process continues to retrieve information. Otherwise, it ends the process.

        Args:
            state (messages): The current state

        Returns:
            str: A decision to either "continue" the retrieval process or "end" it
        """

        print("---DECIDE TO RETRIEVE---")
        messages = state["messages"]
        last_message = messages[-1]

        # If there is no function call, then we finish
        if "function_call" not in last_message.additional_kwargs:
            print("---DECISION: DO NOT RETRIEVE / DONE---")
            return "end"
        # Otherwise there is a function call, so we continue
        else:
            print("---DECISION: RETRIEVE---")
            return "continue"

{% endhighlight %}

#### grade_documents node
{% highlight c++ linenos %}
    def grade_documents(state):
        """
        Determines whether the retrieved documents are relevant to the question.

        Args:
            state (messages): The current state

        Returns:
            str: A decision for whether the documents are relevant or not
        """

        print("---CHECK RELEVANCE---")

        # Data model
        class grade(BaseModel):
            """Binary score for relevance check."""

            binary_score: str = Field(description="Relevance score 'yes' or 'no'")

        # LLM
        model = ChatOpenAI(
            model_name="gpt-3.5-turbo",
            temperature=0,
        )

        # Tool
        grade_tool_oai = convert_to_openai_tool(grade)

        # LLM with tool and enforce invocation
        llm_with_tool = model.bind(
            tools=[convert_to_openai_tool(grade_tool_oai)],
            tool_choice={"type": "function", "function": {"name": "grade"}},
        )

        # Parser
        parser_tool = PydanticToolsParser(tools=[grade])

        # Prompt
        prompt = PromptTemplate(
            template="""You are a grader assessing relevance of a retrieved document to a user question. \n 
            Here is the retrieved document: \n\n {context} \n\n
            Here is the user question: {question} \n
            If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \n
            Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.""",
            input_variables=["context", "question"],
        )

        # Chain
        chain = prompt | llm_with_tool | parser_tool

        messages = state["messages"]
        last_message = messages[-1]

        question = messages[0].content
        docs = last_message.content

        score = chain.invoke({"question": question, "context": docs})

        grade = score[0].binary_score

        if grade == "yes":
            print("---DECISION: DOCS RELEVANT---")
            return "yes"

        else:
            print("---DECISION: DOCS NOT RELEVANT---")
            print(score[0].binary_score)
            return "no"
{% endhighlight %}

#### generate node
{% highlight c++ linenos %}
    def generate(state):
        """
        Generate answer

        Args:
            state (messages): The current state

        Returns:
            dict: The updated state with re-phrased question
        """
        print("---GENERATE---")
        messages = state["messages"]
        question = messages[0].content
        last_message = messages[-1]

        question = messages[0].content
        docs = last_message.content

        # Prompt
        prompt = hub.pull("rlm/rag-prompt")

        # LLM
        llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)

        # Post-processing
        def format_docs(docs):
            return "\n\n".join(doc.page_content for doc in docs)

        # Chain
        rag_chain = prompt | llm | StrOutputParser()

        # Run
        response = rag_chain.invoke({"context": docs, "question": question})
        return {"messages": [response]}
{% endhighlight %}

#### rewrite node
{% highlight c++ linenos %}
    def rewrite(state):
        """
        Transform the query to produce a better question.

        Args:
            state (messages): The current state

        Returns:
            dict: The updated state with re-phrased question
        """

        print("---TRANSFORM QUERY---")
        messages = state["messages"]

        question = messages[0].content

        msg = [
            HumanMessage(
                content=f""" \n 
        Look at the input and try to reason about the underlying semantic intent / meaning. \n 
        Here is the initial question:
        \n ------- \n
        {question} 
        \n ------- \n
        Formulate an improved question: """,
            )
        ]

        # Grader
        model = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)
        response = model.invoke(msg)
        return {"messages": [response]}

{% endhighlight %}

### Graph / Workflow 
    {% highlight c++ linenos %}
    from langgraph.graph import END, StateGraph

    # Define a new graph
    workflow = StateGraph(AgentState)

    # Define the nodes we will cycle between
    workflow.add_node("agent", agent)  # agent
    workflow.add_node("retrieve", retrieve)  # retrieval
    workflow.add_node("rewrite", rewrite)  # retrieval
    workflow.add_node("generate", generate)  # retrieval


    # Call agent node to decide to retrieve or not
    workflow.set_entry_point("agent")

    # Decide whether to retrieve
    workflow.add_conditional_edges(
        "agent",
        # Assess agent decision
        should_retrieve,
        {
            # Call tool node
            "continue": "retrieve",
            "end": END,
        },
    )

    # Edges taken after the `action` node is called.
    workflow.add_conditional_edges(
        "retrieve",
        # Assess agent decision
        grade_documents,
        {
            "yes": "generate",
            "no": "rewrite",
        },
    )
    workflow.add_edge("generate", END)
    workflow.add_edge("rewrite", "agent")

    # Compile
    app = workflow.compile()
{% endhighlight %}

### User Input and Generation
{% highlight c++ linenos %}
    import pprint
    from langchain_core.messages import HumanMessage

    inputs = {"messages": [HumanMessage(content="Tell me about langgraph")]}
    for output in app.stream(inputs):
        for key, value in output.items():
            pprint.pprint(f"Output from node '{key}':")
            pprint.pprint("---")
            pprint.pprint(value, indent=2, width=80, depth=None)
        pprint.pprint("\n---\n")

{% endhighlight %}
```
---CALL AGENT---
"Output from node 'agent':"
'---'
{ 'messages': [ AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{"query":"langgraph"}', 'name': 'retrieve_blog_posts'}})]}
'\n---\n'
---DECIDE TO RETRIEVE---
---DECISION: RETRIEVE---
---EXECUTE RETRIEVAL---
"Output from node 'retrieve':"
'---'
{ 'messages': [ FunctionMessage(content='$$\n\n$$\n\n$$\n\n$$', name='retrieve_blog_posts')]}
'\n---\n'
---CHECK RELEVANCE---
---DECISION: DOCS NOT RELEVANT---
no
---TRANSFORM QUERY---
"Output from node 'rewrite':"
'---'
{ 'messages': [ AIMessage(content='What is the purpose or function of langgraph?')]}
'\n---\n'
---CALL AGENT---
"Output from node 'agent':"
'---'
{ 'messages': [ AIMessage(content='I couldn\'t find specific information about "langgraph" in Lilian Weng\'s blog posts. Could you provide more context or details about langgraph so I can better assist you?')]}
'\n---\n'
---DECIDE TO RETRIEVE---
---DECISION: DO NOT RETRIEVE / DONE---
"Output from node '__end__':"
'---'
{ 'messages': [ HumanMessage(content='Tell me about langgraph'),
                AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{"query":"langgraph"}', 'name': 'retrieve_blog_posts'}}),
                FunctionMessage(content='$$\n\n$$\n\n$$\n\n$$', name='retrieve_blog_posts'),
                AIMessage(content='What is the purpose or function of langgraph?'),
                AIMessage(content='I couldn\'t find specific information about "langgraph" in Lilian Weng\'s blog posts. Could you provide more context or details about langgraph so I can better assist you?')]}
'\n---\n'
```



{% highlight c++ linenos %}
    inputs = {"messages": [HumanMessage(content="Differentiate between agents and chain in langchain")]}
{% endhighlight %}
```
OUTPUT

---CALL AGENT---
"Output from node 'agent':"
'---'
{ 'messages': [ AIMessage(content='In Langchain, an "agent" refers to an entity that interacts with the Langchain network to perform various tasks, such as executing smart contracts, processing transactions, or providing services. Agents in Langchain can be autonomous entities that act on behalf of users or organizations to carry out specific functions within the network.\n\nOn the other hand, a "chain" in Langchain typically refers to the blockchain network itself. It is the decentralized and distributed ledger that stores transaction data, smart contracts, and other information in a secure and immutable manner. The chain in Langchain is responsible for maintaining the integrity of the network, validating transactions, and ensuring consensus among network participants.\n\nIn summary, agents are the entities that interact with the Langchain network to perform tasks, while the chain represents the underlying blockchain infrastructure that facilitates these interactions and maintains the network\'s operations.')]}
'\n---\n'
---DECIDE TO RETRIEVE---
---DECISION: DO NOT RETRIEVE / DONE---
"Output from node '__end__':"
'---'
{ 'messages': [ HumanMessage(content='Differentiate between agents and chain in langchain'),
                AIMessage(content='In Langchain, an "agent" refers to an entity that interacts with the Langchain network to perform various tasks, such as executing smart contracts, processing transactions, or providing services. Agents in Langchain can be autonomous entities that act on behalf of users or organizations to carry out specific functions within the network.\n\nOn the other hand, a "chain" in Langchain typically refers to the blockchain network itself. It is the decentralized and distributed ledger that stores transaction data, smart contracts, and other information in a secure and immutable manner. The chain in Langchain is responsible for maintaining the integrity of the network, validating transactions, and ensuring consensus among network participants.\n\nIn summary, agents are the entities that interact with the Langchain network to perform tasks, while the chain represents the underlying blockchain infrastructure that facilitates these interactions and maintains the network\'s operations.')]}
'\n---\n'
```


{% highlight c++ linenos %}
    inputs = {"messages": [HumanMessage(content="Differentiate zero shot and few shot prompting from the blog posts")]}
{% endhighlight %}
```OUTPUT

---CALL AGENT---
"Output from node 'agent':"
'---'
{ 'messages': [ AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{"query":"zero shot prompting vs few shot prompting"}', 'name': 'retrieve_blog_posts'}})]}
'\n---\n'
---DECIDE TO RETRIEVE---
---DECISION: RETRIEVE---
---EXECUTE RETRIEVAL---
"Output from node 'retrieve':"
'---'
{ 'messages': [ FunctionMessage(content="Basic Prompting#\nZero-shot and few-shot learning are two most basic approaches for prompting the model, pioneered by many LLM papers and commonly used for benchmarking LLM performance.\nZero-Shot#\nZero-shot learning is to simply feed the task text to the model and ask for results.\n(All the sentiment analysis examples are from SST-2)\nText: i'll bet the video game is a lot more fun than the film.\n\nInstruction Prompting#\nThe purpose of presenting few-shot examples in the prompt is to explain our intent to the model; in other words, describe the task instruction to the model in the form of demonstrations. However, few-shot can be expensive in terms of token usage and restricts the input length due to limited context length. So, why not just give the instruction directly?\n\nZero-shot generation: This is to find a number of prompts that can trigger harmful output conditioned on a preset prompt.\nStochastic few-shot generation: The red team prompts found from the above step are then used as few-shot examples to generate more similar cases. Each zero-shot test case might be selected in few-shot examples with a probability $\\propto \\exp(r(\\mathbf{x}, \\mathbf{y}) / \\tau)$\n\nZero-shot generation: This is to find a number of prompts that can trigger harmful output conditioned on a preset prompt.", name='retrieve_blog_posts')]}
'\n---\n'
---CHECK RELEVANCE---
---DECISION: DOCS RELEVANT---
---GENERATE---
"Output from node 'generate':"
'---'
{ 'messages': [ 'Zero-shot learning involves feeding the task text to the '
                'model and asking for results directly. Few-shot prompting, on '
                'the other hand, involves presenting a few examples in the '
                'prompt to explain the task intent to the model. Zero-shot '
                'generation focuses on finding prompts that can trigger '
                'harmful output based on a preset prompt.']}
'\n---\n'
"Output from node '__end__':"
'---'
{ 'messages': [ HumanMessage(content='Differentiate zero shot and few shot prompting from the blog post'),
                AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{"query":"zero shot prompting vs few shot prompting"}', 'name': 'retrieve_blog_posts'}}),
                FunctionMessage(content="Basic Prompting#\nZero-shot and few-shot learning are two most basic approaches for prompting the model, pioneered by many LLM papers and commonly used for benchmarking LLM performance.\nZero-Shot#\nZero-shot learning is to simply feed the task text to the model and ask for results.\n(All the sentiment analysis examples are from SST-2)\nText: i'll bet the video game is a lot more fun than the film.\n\nInstruction Prompting#\nThe purpose of presenting few-shot examples in the prompt is to explain our intent to the model; in other words, describe the task instruction to the model in the form of demonstrations. However, few-shot can be expensive in terms of token usage and restricts the input length due to limited context length. So, why not just give the instruction directly?\n\nZero-shot generation: This is to find a number of prompts that can trigger harmful output conditioned on a preset prompt.\nStochastic few-shot generation: The red team prompts found from the above step are then used as few-shot examples to generate more similar cases. Each zero-shot test case might be selected in few-shot examples with a probability $\\propto \\exp(r(\\mathbf{x}, \\mathbf{y}) / \\tau)$\n\nZero-shot generation: This is to find a number of prompts that can trigger harmful output conditioned on a preset prompt.", name='retrieve_blog_posts'),
                'Zero-shot learning involves feeding the task text to the '
                'model and asking for results directly. Few-shot prompting, on '
                'the other hand, involves presenting a few examples in the '
                'prompt to explain the task intent to the model. Zero-shot '
                'generation focuses on finding prompts that can trigger '
                'harmful output based on a preset prompt.']}
'\n---\n'
```

## Conclusions
## References


